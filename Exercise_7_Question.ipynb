{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11563
        },
        "outputId": "0387d9b6-516f-410d-e2e4-67824c502f74"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), include_top = False, weights = None)\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-07 04:58:22--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.234.128, 2607:f8b0:4001:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.234.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   139MB/s    in 0.6s    \n",
            "\n",
            "2019-06-07 04:58:23 (139 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57ee2428-5849-49cb-a1fa-3e3510275dde"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc') > 0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8520
        },
        "outputId": "16c38da6-914d-41d9-8f9c-c2128a6355dd"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "61d4ce43-ca87-44b3-f45c-c6e937dd7515"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-07 04:58:48--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.200.128, 2607:f8b0:4001:c15::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.200.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   138MB/s    in 1.0s    \n",
            "\n",
            "2019-06-07 04:58:49 (138 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-06-07 04:58:50--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c12::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-06-07 04:58:51 (110 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "955ca3fd-6317-4a79-d6dc-5105d6d11323"
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses'\n",
        "train_humans_dir = '/tmp/training/humans'\n",
        "validation_horses_dir = '/tmp/validation/horses'\n",
        "validation_humans_dir = '/tmp/validation/humans'\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "520139ad-05f9-4a4b-dfc7-9a9e231ebf86"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0 / 255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1703
        },
        "outputId": "67a77b96-fea7-46a5-ae82-48b9287b13c0"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "history = model.fit_generator(train_generator, epochs=100, validation_data=validation_generator, callbacks=[myCallback()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 155ms/step - loss: 0.0039 - acc: 1.0000\n",
            "52/52 [==============================] - 15s 292ms/step - loss: 0.2493 - acc: 0.8939 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 104ms/step - loss: 2.6261e-04 - acc: 1.0000\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.1032 - acc: 0.9562 - val_loss: 2.6261e-04 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.0010 - acc: 1.0000\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0855 - acc: 0.9718 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 105ms/step - loss: 0.0037 - acc: 0.9961\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0458 - acc: 0.9786 - val_loss: 0.0037 - val_acc: 0.9961\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 0.0086 - acc: 0.9961\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0663 - acc: 0.9718 - val_loss: 0.0086 - val_acc: 0.9961\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.0969 - acc: 0.9727\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0329 - acc: 0.9893 - val_loss: 0.0969 - val_acc: 0.9727\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.0310 - acc: 0.9883\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0310 - acc: 0.9893 - val_loss: 0.0310 - val_acc: 0.9883\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 105ms/step - loss: 0.1063 - acc: 0.9844\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0336 - acc: 0.9883 - val_loss: 0.1063 - val_acc: 0.9844\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.0286 - acc: 0.9961\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0345 - acc: 0.9883 - val_loss: 0.0286 - val_acc: 0.9961\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 1s 104ms/step - loss: 0.1069 - acc: 0.9844\n",
            "52/52 [==============================] - 11s 221ms/step - loss: 0.0305 - acc: 0.9864 - val_loss: 0.1069 - val_acc: 0.9844\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.0057 - acc: 0.9961\n",
            "52/52 [==============================] - 11s 219ms/step - loss: 0.0199 - acc: 0.9942 - val_loss: 0.0057 - val_acc: 0.9961\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 104ms/step - loss: 0.0379 - acc: 0.9922\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0333 - acc: 0.9873 - val_loss: 0.0379 - val_acc: 0.9922\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.2161 - acc: 0.9688\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0335 - acc: 0.9932 - val_loss: 0.2161 - val_acc: 0.9688\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.0434 - acc: 0.9922\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0342 - acc: 0.9873 - val_loss: 0.0434 - val_acc: 0.9922\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.1895 - acc: 0.9727\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0466 - acc: 0.9912 - val_loss: 0.1895 - val_acc: 0.9727\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 105ms/step - loss: 0.2267 - acc: 0.9766\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0338 - acc: 0.9844 - val_loss: 0.2267 - val_acc: 0.9766\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 1s 105ms/step - loss: 0.1335 - acc: 0.9844\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0320 - acc: 0.9912 - val_loss: 0.1335 - val_acc: 0.9844\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.4546 - acc: 0.9531\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0175 - acc: 0.9942 - val_loss: 0.4546 - val_acc: 0.9531\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.1197 - acc: 0.9766\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0403 - acc: 0.9893 - val_loss: 0.1197 - val_acc: 0.9766\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.4407 - acc: 0.9531\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0537 - acc: 0.9854 - val_loss: 0.4407 - val_acc: 0.9531\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 0.3448 - acc: 0.9570\n",
            "52/52 [==============================] - 11s 220ms/step - loss: 0.0230 - acc: 0.9932 - val_loss: 0.3448 - val_acc: 0.9570\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.3035 - acc: 0.9570\n",
            "52/52 [==============================] - 11s 214ms/step - loss: 0.0138 - acc: 0.9932 - val_loss: 0.3035 - val_acc: 0.9570\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.2657 - acc: 0.9648\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0235 - acc: 0.9951 - val_loss: 0.2657 - val_acc: 0.9648\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.6280 - acc: 0.9531\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0441 - acc: 0.9883 - val_loss: 0.6280 - val_acc: 0.9531\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.2932 - acc: 0.9570\n",
            "52/52 [==============================] - 11s 215ms/step - loss: 0.0455 - acc: 0.9922 - val_loss: 0.2932 - val_acc: 0.9570\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.1636 - acc: 0.9805\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0119 - acc: 0.9951 - val_loss: 0.1636 - val_acc: 0.9805\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 1s 104ms/step - loss: 0.2695 - acc: 0.9648\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0220 - acc: 0.9932 - val_loss: 0.2695 - val_acc: 0.9648\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 104ms/step - loss: 0.1303 - acc: 0.9805\n",
            "52/52 [==============================] - 11s 218ms/step - loss: 0.0351 - acc: 0.9903 - val_loss: 0.1303 - val_acc: 0.9805\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.1442 - acc: 0.9844\n",
            "52/52 [==============================] - 11s 216ms/step - loss: 0.0194 - acc: 0.9942 - val_loss: 0.1442 - val_acc: 0.9844\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 1s 104ms/step - loss: 0.0688 - acc: 0.9883\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0076 - acc: 0.9971 - val_loss: 0.0688 - val_acc: 0.9883\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 104ms/step - loss: 0.0649 - acc: 0.9922\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "52/52 [==============================] - 11s 217ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0649 - val_acc: 0.9922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "702132a4-3607-41c7-e965-b11ac4770bf0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4zgJhCt9x3GcBMKVvuM4TgLx/z42lM6hwAftAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}